{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJyKooinlS+0X3LrY0/+FT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IT21174230/ML-Journey/blob/main/RNN_TEXT_PREDICTION_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. convert text into lower case and split into words.\n",
        "\n",
        "2. enumerate to map all the unique words into integers.\n",
        "\n",
        "3. create a training set with input sequence and target output sequence using window sliding method.\n",
        "\n",
        "4. build the model, compile and test.\n",
        "\n",
        "\n",
        "\n",
        "lmao the shit this predictsüíÄüíÄ"
      ],
      "metadata": {
        "id": "t_PM7b3xvO7L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4lTQW_ZsGZ6",
        "outputId": "6c62cb50-59f4-4be7-b123-0d7fc4c5bcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_data='/content/drive/MyDrive/excerpt.txt'\n",
        "\n",
        "with open(seq_data, 'r') as file:\n",
        "  text=file.read().lower().split()\n",
        "\n"
      ],
      "metadata": {
        "id": "SkFF8OPHsnoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text=preprocess(text)\n",
        "unique_words=sorted(list(set(text)))\n",
        "\n",
        "word_2_int={word:i for i, word in enumerate(unique_words)}\n",
        "int_2_word={i:word for i, word in enumerate(unique_words)}\n",
        "\n",
        "print(int_2_word)\n",
        "\n",
        "print(word_2_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-v_G1Ymtjcd",
        "outputId": "9ba70b46-3ad3-427f-ccab-4138d14b84ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'a', 1: 'able', 2: 'about', 3: 'about,', 4: 'about?!‚Äù', 5: 'absolutely', 6: 'absorbing', 7: 'across', 8: 'acted', 9: 'actually', 10: 'afar,', 11: 'afraid', 12: 'after', 13: 'afterward.', 14: 'again', 15: 'again!', 16: 'again.', 17: 'against', 18: 'age', 19: 'aggravation,', 20: 'ago,', 21: 'ah‚Ä¶never', 22: 'all', 23: 'all,', 24: 'all.', 25: 'allowed', 26: 'all‚Äîa', 27: 'almost', 28: 'alone', 29: 'already', 30: 'also', 31: 'an', 32: 'and', 33: 'anger', 34: 'angrily', 35: 'another', 36: 'ants', 37: 'any', 38: 'anyone', 39: 'appalled', 40: 'appearances.', 41: 'applied,', 42: 'applying', 43: 'are', 44: 'arm', 45: 'armored', 46: 'arms', 47: 'arms,', 48: 'arms.', 49: 'around', 50: 'array', 51: 'array?!', 52: 'array‚Ä¶', 53: 'art.', 54: 'as', 55: 'aside', 56: 'ask', 57: 'asked', 58: 'at', 59: 'ate', 60: 'automaton,', 61: 'automatons', 62: 'awake,', 63: 'away', 64: 'away,', 65: 'away‚Ä¶‚Äù', 66: 'back', 67: 'back,', 68: 'back.', 69: 'backbone,', 70: 'backlash', 71: 'back‚Äîthat', 72: 'bad', 73: 'bag,', 74: 'bamboo', 75: 'bandages', 76: 'bandaging', 77: 'bare', 78: 'bared', 79: 'barely', 80: 'barrier', 81: 'bat', 82: 'be', 83: 'be?!', 84: 'because', 85: 'bed', 86: 'bed,', 87: 'bed.', 88: 'bedroom.', 89: 'bedside,', 90: 'bedside.', 91: 'been', 92: 'before', 93: 'before.', 94: 'began', 95: 'begrudge', 96: 'behind', 97: 'being', 98: 'being‚Ä¶', 99: 'believed', 100: 'belly', 101: 'belonged', 102: 'belt', 103: 'beside', 104: 'better?', 105: 'between', 106: 'big,', 107: 'billowing', 108: 'birth', 109: 'bit', 110: 'bit,', 111: 'bitter', 112: 'bitter!‚Äù', 113: 'blazing', 114: 'bleeding.', 115: 'blew', 116: 'blink', 117: 'blood', 118: 'blood,', 119: 'blood.', 120: 'blood‚Ä¶', 121: 'bloomed', 122: 'blowing', 123: 'blue,', 124: 'body', 125: 'body,', 126: 'body.', 127: 'bone.', 128: 'bones', 129: 'born', 130: 'born,', 131: 'both', 132: 'bothering', 133: 'boundary,', 134: 'bow', 135: 'bowl', 136: 'brave', 137: 'breakfast,', 138: 'breath', 139: 'breathing', 140: 'breaths', 141: 'brewed', 142: 'bridge‚Äôs', 143: 'brilliant', 144: 'broad', 145: 'broke', 146: 'broken', 147: 'brother', 148: 'brother.‚Äù', 149: 'brothers.‚Äù', 150: 'brought', 151: 'bruises', 152: 'burst', 153: 'but', 154: 'but,', 155: 'by', 156: 'called', 157: 'came', 158: 'can', 159: 'candle.', 160: 'candlelight,', 161: 'candy', 162: 'care', 163: 'care.', 164: 'carried', 165: 'carrying', 166: 'catch', 167: 'caught', 168: 'cavalry', 169: 'ceaselessly,', 170: 'cedarwood.', 171: 'center.', 172: 'certain', 173: 'change', 174: 'chaste', 175: 'cheating', 176: 'chest,', 177: 'chest.', 178: 'chin', 179: 'chiye', 180: 'chu', 181: 'circle', 182: 'circumstances,', 183: 'clanking', 184: 'clean.', 185: 'clear', 186: 'clearly', 187: 'close', 188: 'closed', 189: 'closer', 190: 'closer,', 191: 'clothes.', 192: 'clothing', 193: 'cold', 194: 'cold,', 195: 'cold?!', 196: 'colder', 197: 'colder,', 198: 'cold‚Ä¶‚Äù', 199: 'collar', 200: 'collars', 201: 'come', 202: 'complaint.', 203: 'completely', 204: 'composed', 205: 'congee‚Ä¶‚Äù', 206: 'conjured', 207: 'considered', 208: 'continued', 209: 'continuously', 210: 'control.', 211: 'cool', 212: 'coppery', 213: 'core', 214: 'corner', 215: 'corners', 216: 'corpse.', 217: 'coughed', 218: 'could', 219: 'couldn‚Äôt', 220: 'could‚Äôve', 221: 'court', 222: 'covers', 223: 'cracked', 224: 'cradled', 225: 'cried‚Äîthat', 226: 'cry', 227: 'cultivation,', 228: 'curled', 229: 'currently', 230: 'curse', 231: 'cursed', 232: 'curtains.', 233: 'cut', 234: 'cut,', 235: 'cutting', 236: 'dajing.', 237: 'dajing.‚Äù', 238: 'damage.', 239: 'dare', 240: 'dared', 241: 'dare‚Ä¶', 242: 'daring', 243: 'day', 244: 'day,', 245: 'days', 246: 'daze.', 247: 'dazzled', 248: 'dead!', 249: 'dead.', 250: 'death,', 251: 'death.', 252: 'deaths.', 253: 'decades.', 254: 'deeper', 255: 'demand:', 256: 'descent', 257: 'desire', 258: 'devoured', 259: 'did', 260: 'didn‚Äôt', 261: 'die', 262: 'die!‚Äù', 263: 'died', 264: 'difficult', 265: 'dignity', 266: 'direction', 267: 'disappeared', 268: 'disciples', 269: 'discipline', 270: 'discomfort,', 271: 'discreetly', 272: 'disintegrate,', 273: 'dismounted.', 274: 'dispersed.', 275: 'distance', 276: 'distance.‚Äù', 277: 'distinguishable.', 278: 'do', 279: 'do.', 280: 'dog!', 281: 'dog,', 282: 'doing', 283: 'doing,', 284: 'done', 285: 'don‚Äôt', 286: 'door', 287: 'door,', 288: 'doorway,', 289: 'down', 290: 'down.', 291: 'downward', 292: 'doze,', 293: 'dozed', 294: 'drafty', 295: 'dragged', 296: 'dragging,', 297: 'drain', 298: 'drawn', 299: 'dream.', 300: 'dreams', 301: 'drenched', 302: 'dress', 303: 'drew', 304: 'drooped,', 305: 'dumbfounded.', 306: 'during', 307: 'dust', 308: 'dyed', 309: 'each', 310: 'eat', 311: 'ecstasy', 312: 'egg', 313: 'elder', 314: 'eldest', 315: 'elemental', 316: 'elements', 317: 'else', 318: 'embrace.‚Äù', 319: 'embracing', 320: 'emotions', 321: 'emperor', 322: 'empty', 323: 'empty,', 324: 'encounter', 325: 'end;', 326: 'ended', 327: 'enemy,', 328: 'energy', 329: 'energy,', 330: 'energy.', 331: 'enormous', 332: 'enraged', 333: 'enter', 334: 'entire', 335: 'entwined', 336: 'entwined,', 337: 'error‚Ä¶', 338: 'escaped', 339: 'essence', 340: 'eternal', 341: 'even', 342: 'every', 343: 'everything', 344: 'exhaustion', 345: 'existed', 346: 'exploded', 347: 'expression', 348: 'extent', 349: 'extremely', 350: 'eye,', 351: 'eyebrows', 352: 'eyelash.', 353: 'eyelashes', 354: 'eyes', 355: 'eyes,', 356: 'eyes.', 357: 'eyes‚Äîforever.‚Äù', 358: 'face', 359: 'face.', 360: 'faced', 361: 'faces', 362: 'fact', 363: 'fall', 364: 'fallen', 365: 'familiar', 366: 'familiarity', 367: 'fangxu', 368: 'fangxu.', 369: 'far', 370: 'favored', 371: 'fed', 372: 'feed', 373: 'feeding', 374: 'feel', 375: 'feet', 376: 'fell', 377: 'felt', 378: 'festered,', 379: 'festering.', 380: 'fever', 381: 'feverish', 382: 'feverish,', 383: 'few', 384: 'fierce', 385: 'figure,', 386: 'figuring', 387: 'filled', 388: 'finally', 389: 'finally,', 390: 'fine', 391: 'finished', 392: 'fireworks', 393: 'first', 394: 'five', 395: 'flame', 396: 'flame,', 397: 'flared', 398: 'fleeting', 399: 'flesh', 400: 'flora', 401: 'floral', 402: 'flow', 403: 'flowed', 404: 'flower', 405: 'flowers', 406: 'flushed', 407: 'fluttered', 408: 'fluttering', 409: 'foggy', 410: 'follow', 411: 'followed', 412: 'followed,', 413: 'following,', 414: 'foot', 415: 'for', 416: 'fortunately,', 417: 'forward.', 418: 'found', 419: 'fresh', 420: 'from', 421: 'front', 422: 'frowned,', 423: 'fucking', 424: 'further', 425: 'further,', 426: 'fuzzy.', 427: 'gall', 428: 'gather', 429: 'gaze', 430: 'gazed', 431: 'generation', 432: 'gently', 433: 'gently.', 434: 'get', 435: 'getting', 436: 'ghost', 437: 'glanced', 438: 'gnawing', 439: 'go', 440: 'goddamn', 441: 'going', 442: 'gone', 443: 'gone,', 444: 'gone.', 445: 'good,', 446: 'goodness', 447: 'got', 448: 'grab', 449: 'grass', 450: 'grave', 451: 'grew', 452: 'grimaced,', 453: 'groan', 454: 'groaned', 455: 'groaning', 456: 'ground', 457: 'growing', 458: 'grown', 459: 'gulp', 460: 'habit', 461: 'had', 462: 'had,', 463: 'hadn‚Äôt', 464: 'hair', 465: 'half', 466: 'half-asleep,', 467: 'half-open', 468: 'halfway', 469: 'hand,', 470: 'handle', 471: 'happened', 472: 'hard', 473: 'has', 474: 'hate', 475: 'hated', 476: 'hatred,', 477: 'have', 478: 'have‚Ä¶made', 479: 'having', 480: 'hazy', 481: 'he', 482: 'head', 483: 'head.', 484: 'headed', 485: 'healing', 486: 'healing.', 487: 'healthy', 488: 'hear', 489: 'heard', 490: 'hearing', 491: 'heart', 492: 'heart.', 493: 'heat', 494: 'heavier', 495: 'heavier.', 496: 'held', 497: 'hell', 498: 'hell.', 499: 'help', 500: 'helped', 501: 'her', 502: 'here', 503: 'here,', 504: 'here.', 505: 'here.‚Äù', 506: 'heroes.‚Äù', 507: 'he‚Äôd', 508: 'hidden', 509: 'high', 510: 'him', 511: 'him,', 512: 'him.', 513: 'himself', 514: 'himself,', 515: 'himself.', 516: 'himself:', 517: 'him‚Äîthis', 518: 'his', 519: 'his.', 520: 'hold', 521: 'holding', 522: 'hongyan', 523: 'hope', 524: 'horror,', 525: 'hot', 526: 'hour', 527: 'hour,', 528: 'how', 529: 'however,', 530: 'humid', 531: 'hundred', 532: 'i', 533: 'ice.', 534: 'idly', 535: 'if', 536: 'ignore', 537: 'illuminating', 538: 'imagined.', 539: 'immediately', 540: 'in', 541: 'in,', 542: 'in.', 543: 'indeed', 544: 'indignation,', 545: 'indulgence', 546: 'inexplicably,', 547: 'infected', 548: 'infirmary', 549: 'injury', 550: 'injury.', 551: 'inside', 552: 'insisted', 553: 'instant,', 554: 'instead', 555: 'instead,', 556: 'instead.', 557: 'integrity', 558: 'intensity,', 559: 'intensive', 560: 'intimate', 561: 'into', 562: 'involuntary', 563: 'irritation', 564: 'is', 565: 'it', 566: 'it,', 567: 'it.', 568: 'its', 569: 'itself.', 570: 'it‚Äôs', 571: 'it‚Ä¶', 572: 'jaw', 573: 'jealousy,', 574: 'jerking.', 575: 'joy', 576: 'just', 577: 'keeping', 578: 'kept', 579: 'kick', 580: 'kicked', 581: 'kind', 582: 'kiss', 583: 'kissed,', 584: 'knew', 585: 'knife', 586: 'know', 587: 'know.', 588: 'labored', 589: 'lad', 590: 'laid', 591: 'last', 592: 'late', 593: 'later,', 594: 'laughed', 595: 'lay', 596: 'layer', 597: 'lazily', 598: 'lean,', 599: 'leaned', 600: 'least.', 601: 'leave', 602: 'leaves.', 603: 'leaving', 604: 'left', 605: 'leg', 606: 'legs,', 607: 'let', 608: 'libei', 609: 'lie', 610: 'life', 611: 'life,', 612: 'life.', 613: 'life?', 614: 'lifeblood', 615: 'lifetime', 616: 'lifetime,', 617: 'lifetime.', 618: 'lifted', 619: 'light', 620: 'light,', 621: 'lightly', 622: 'lightning,', 623: 'like', 624: 'line', 625: 'lingering', 626: 'lips', 627: 'lips,', 628: 'lips.', 629: 'little', 630: 'location', 631: 'loneliness', 632: 'long', 633: 'longer', 634: 'longer.‚Äù', 635: 'longer‚Ä¶', 636: 'look', 637: 'looked', 638: 'lose', 639: 'lost', 640: 'lotus', 641: 'love', 642: 'loved', 643: 'lucid,', 644: 'lying', 645: 'm-mo', 646: 'madam', 647: 'made', 648: 'maintain', 649: 'make', 650: 'man', 651: 'man,', 652: 'man.', 653: 'many', 654: 'marched,', 655: 'matter', 656: 'matter.', 657: 'me', 658: 'meaning', 659: 'meat', 660: 'medicine', 661: 'medicine,', 662: 'medicine.‚Äù', 663: 'mei', 664: 'mei.', 665: 'memories', 666: 'men', 667: 'mend', 668: 'merely', 669: 'metal', 670: 'might', 671: 'mind', 672: 'mind.', 673: 'mind.‚Äù', 674: 'mind:', 675: 'missed', 676: 'mist', 677: 'mistress', 678: 'mo', 679: 'moment', 680: 'moment,', 681: 'monument', 682: 'monument,', 683: 'moonlight', 684: 'moral', 685: 'more', 686: 'morning', 687: 'morning,', 688: 'moron?!', 689: 'mortal', 690: 'most', 691: 'most,', 692: 'mother?‚Äù', 693: 'mottled', 694: 'mountains', 695: 'mountains,', 696: 'mountains.', 697: 'mouth', 698: 'mouth.', 699: 'mouthful', 700: 'mouthfuls.', 701: 'moved,', 702: 'movements', 703: 'moving', 704: 'much', 705: 'muddled', 706: 'mulishly', 707: 'murk', 708: 'murmured,', 709: 'murmuring,', 710: 'muscles,', 711: 'muster', 712: 'muttered.', 713: 'my', 714: 'nagging', 715: 'name', 716: 'names', 717: 'naturally,', 718: 'nature', 719: 'needed.', 720: 'never', 721: 'never-ending', 722: 'new', 723: 'next', 724: 'night', 725: 'night,', 726: 'night.', 727: 'no', 728: 'noise', 729: 'none', 730: 'nonsense', 731: 'not', 732: 'nothing', 733: 'now', 734: 'numb.', 735: 'occurred', 736: 'of', 737: 'off', 738: 'off.', 739: 'offense,', 740: 'okay‚Ä¶‚Ä¶‚Äù', 741: 'old', 742: 'on', 743: 'on,', 744: 'once', 745: 'one', 746: 'ones.', 747: 'only', 748: 'onto', 749: 'open', 750: 'open,', 751: 'open.', 752: 'opened', 753: 'or', 754: 'other', 755: 'others,', 756: 'out', 757: 'out,', 758: 'out.', 759: 'out?', 760: 'over', 761: 'over.', 762: 'own', 763: 'pain,', 764: 'pain.', 765: 'pained,', 766: 'palace.', 767: 'pale,', 768: 'paled,', 769: 'palm', 770: 'palm,', 771: 'palms', 772: 'panic.', 773: 'paper', 774: 'part', 775: 'parting', 776: 'passing', 777: 'passion', 778: 'past', 779: 'past,', 780: 'past.', 781: 'patiently', 782: 'peaceful', 783: 'peak', 784: 'people', 785: 'period', 786: 'person', 787: 'person.', 788: 'person‚Äôs', 789: 'pettily.', 790: 'phrase', 791: 'physical', 792: 'picked', 793: 'picture', 794: 'piece', 795: 'pillars,', 796: 'pillow', 797: 'pity', 798: 'place', 799: 'place,', 800: 'placed', 801: 'places', 802: 'places,', 803: 'point', 804: 'pointed', 805: 'pond', 806: 'pond,', 807: 'pond.', 808: 'pool', 809: 'pool.', 810: 'pooled', 811: 'possess.', 812: 'possible.', 813: 'poured', 814: 'power', 815: 'powerful', 816: 'precious', 817: 'press', 818: 'pressed', 819: 'pressing', 820: 'previous', 821: 'pride?', 822: 'probably', 823: 'problem', 824: 'process', 825: 'process,', 826: 'propped', 827: 'propriety.', 828: 'pulling', 829: 'punishment', 830: 'purpling', 831: 'pursing.', 832: 'pushing', 833: 'put', 834: 'quickly', 835: 'quilt', 836: 'quilt.', 837: 'rain,', 838: 'raising', 839: 'ran', 840: 'ran.', 841: 'ran‚Äôs', 842: 'rapidly', 843: 'rather', 844: 'ravish', 845: 'reach', 846: 'reach.', 847: 'reached', 848: 'reacted', 849: 'reaction', 850: 'real,', 851: 'realize', 852: 'realized', 853: 'really', 854: 'rebirth.', 855: 'reborn,', 856: 'receded.', 857: 'recklessly', 858: 'red.', 859: 'refused', 860: 'region,', 861: 'relations', 862: 'relief.', 863: 'reluctantly,', 864: 'remember', 865: 'remembered', 866: 'reminded', 867: 'resist', 868: 'respond.', 869: 'rest', 870: 'rest.', 871: 'rested', 872: 'restful', 873: 'return', 874: 'returned', 875: 'reunions', 876: 'revealed', 877: 'revealing', 878: 'reverse.', 879: 'rhythm,', 880: 'right', 881: 'right,‚Äù', 882: 'rise', 883: 'rivers', 884: 'robes,', 885: 'rod.', 886: 'room', 887: 'room.', 888: 'rotted', 889: 'roughly,', 890: 'rushed', 891: 'rusty,', 892: 'sacrifice', 893: 'said', 894: 'said,', 895: 'salve', 896: 'same', 897: 'sash', 898: 'sat', 899: 'saw', 900: 'say', 901: 'say,', 902: 'scalp', 903: 'scars', 904: 'scatter,', 905: 'scenario', 906: 'scent', 907: 'scrapped', 908: 'scrutinize', 909: 'sealed', 910: 'see', 911: 'seeing', 912: 'seemed', 913: 'seen', 914: 'seizing', 915: 'self', 916: 'sensation', 917: 'sense', 918: 'sent', 919: 'set', 920: 'setting', 921: 'settled', 922: 'several', 923: 'severe', 924: 'shake', 925: 'shallow', 926: 'shattered,', 927: 'sheets', 928: 'shh‚Ä¶', 929: 'shi', 930: 'shield', 931: 'shines', 932: 'shizun!‚Äù', 933: 'shizun.', 934: 'shizun‚Äôs', 935: 'shock,', 936: 'shone', 937: 'should', 938: 'shoulder.', 939: 'shoulders', 940: 'shoulders.', 941: 'shouting,', 942: 'show', 943: 'showed', 944: 'shuddering', 945: 'shut', 946: 'sichuan', 947: 'sigh', 948: 'sighed,', 949: 'sight', 950: 'signified', 951: 'silent,', 952: 'since', 953: 'single', 954: 'single-mindedly', 955: 'sip', 956: 'sisheng', 957: 'sixteen-year-old', 958: 'skin', 959: 'sky', 960: 'slapped', 961: 'sleep', 962: 'sleep,', 963: 'sleep.', 964: 'sleep?', 965: 'sleeping', 966: 'sleeping.', 967: 'slender', 968: 'slept', 969: 'sliced', 970: 'slightest.', 971: 'slightly', 972: 'slipped', 973: 'sloppily,', 974: 'slowly', 975: 'slumber.', 976: 'small', 977: 'smiled', 978: 'sneak', 979: 'so', 980: 'so,', 981: 'so-called', 982: 'softly', 983: 'solved!‚Äù', 984: 'somber', 985: 'some', 986: 'someone', 987: 'something', 988: 'sorrow', 989: 'sound,', 990: 'speech,', 991: 'speechless.', 992: 'spent', 993: 'spirit', 994: 'spirits', 995: 'spirits.', 996: 'spiritual', 997: 'splashed', 998: 'spoonful', 999: 'spoonfuls', 1000: 'spot.', 1001: 'spot.‚Äù', 1002: 'spots', 1003: 'spread', 1004: 'squinted', 1005: 'stab', 1006: 'staining', 1007: 'stalked', 1008: 'stand', 1009: 'stared.', 1010: 'stars', 1011: 'started', 1012: 'startled,', 1013: 'state', 1014: 'state,', 1015: 'staunch', 1016: 'steady.', 1017: 'steps', 1018: 'sterilizing', 1019: 'stiff', 1020: 'stifled', 1021: 'still', 1022: 'still,', 1023: 'stock-still.', 1024: 'stone', 1025: 'stood', 1026: 'stop', 1027: 'streaks', 1028: 'strikes', 1029: 'stroked', 1030: 'strong', 1031: 'struck', 1032: 'stubborn', 1033: 'stubborn?', 1034: 'stupid', 1035: 'subconsciously', 1036: 'submerged', 1037: 'such', 1038: 'suck', 1039: 'suddenly,', 1040: 'suffered', 1041: 'suining.', 1042: 'sun', 1043: 'sun,', 1044: 'sun.', 1045: 'support', 1046: 'supporting', 1047: 'suppress', 1048: 'sure', 1049: 'sweat', 1050: 'swiftly', 1051: 'swore', 1052: 'take', 1053: 'taking', 1054: 'talking', 1055: 'taste', 1056: 'tasted', 1057: 'taut', 1058: 'taxian\\x02jun,', 1059: 'taxian-jun', 1060: 'technique', 1061: 'technique!', 1062: 'tell', 1063: 'temper', 1064: 'temples,', 1065: 'ten', 1066: 'tender', 1067: 'terrible', 1068: 'test', 1069: 'than', 1070: 'that', 1071: 'that,', 1072: 'that‚Äôs', 1073: 'the', 1074: 'their', 1075: 'them', 1076: 'them,', 1077: 'them.', 1078: 'then', 1079: 'then,', 1080: 'there', 1081: 'these', 1082: 'they', 1083: 'thick', 1084: 'thing', 1085: 'thing.', 1086: 'things', 1087: 'things.', 1088: 'things;', 1089: 'think', 1090: 'thirty-two-year-old', 1091: 'this', 1092: 'this,', 1093: 'this.', 1094: 'this?', 1095: 'those', 1096: 'those‚Äîthose', 1097: 'though', 1098: 'though,', 1099: 'thought', 1100: 'thousand', 1101: 'three', 1102: 'throat', 1103: 'through', 1104: 'through.', 1105: 'throw', 1106: 'throwing', 1107: 'thrown', 1108: 'thump.', 1109: 'tianwen,', 1110: 'time', 1111: 'time,', 1112: 'timelessness', 1113: 'times', 1114: 'times,', 1115: 'tipped', 1116: 'tired', 1117: 'to', 1118: 'to.', 1119: 'together', 1120: 'together.', 1121: 'tongue', 1122: 'tongue.', 1123: 'too', 1124: 'too,', 1125: 'too.', 1126: 'took', 1127: 'top', 1128: 'tore', 1129: 'torn', 1130: 'torrent.', 1131: 'tossing', 1132: 'touch', 1133: 'tousled', 1134: 'toward', 1135: 'towel', 1136: 'to‚Ä¶', 1137: 'transfer', 1138: 'treat', 1139: 'trembling', 1140: 'tried', 1141: 'true', 1142: 'truly', 1143: 'truth.', 1144: 'tucked', 1145: 'turmoil,', 1146: 'turned', 1147: 'turning,', 1148: 'twinge', 1149: 'two', 1150: 'two,', 1151: 'two-faced,', 1152: 'unable', 1153: 'unbroken.', 1154: 'unconscious', 1155: 'unconscious,', 1156: 'unconscious.', 1157: 'under', 1158: 'unevenly', 1159: 'unfortunately,', 1160: 'unique', 1161: 'universe.', 1162: 'unmoving,', 1163: 'unseen', 1164: 'until', 1165: 'unyielding', 1166: 'up', 1167: 'up,', 1168: 'up.', 1169: 'upon', 1170: 'upper', 1171: 'used', 1172: 'using', 1173: 'usual', 1174: 'usually', 1175: 'usually,', 1176: 'utter', 1177: 'utterly', 1178: 'vaguely,', 1179: 'vanished', 1180: 'vaulted', 1181: 'veil', 1182: 'venerable', 1183: 'versa,', 1184: 'very', 1185: 'vestige', 1186: 'vice', 1187: 'vicious', 1188: 'voice', 1189: 'wading', 1190: 'waist', 1191: 'walked', 1192: 'walking', 1193: 'wang‚Äôs', 1194: 'wanning', 1195: 'wanning!‚Äù', 1196: 'wanning,', 1197: 'wanning.', 1198: 'wanning?', 1199: 'wanning‚Äôs', 1200: 'want', 1201: 'wanted,', 1202: 'warmth', 1203: 'warning.', 1204: 'was', 1205: 'was,', 1206: 'washed', 1207: 'wasn‚Äôt', 1208: 'watch', 1209: 'watched.', 1210: 'water', 1211: 'water,', 1212: 'water‚Ä¶', 1213: 'waves', 1214: 'way', 1215: 'we', 1216: 'weakness', 1217: 'weave', 1218: 'weiyu', 1219: 'weiyu?!', 1220: 'well', 1221: 'went', 1222: 'were', 1223: 'west.', 1224: 'wetness', 1225: 'what', 1226: 'when', 1227: 'where', 1228: 'which', 1229: 'while', 1230: 'while,', 1231: 'white', 1232: 'white.', 1233: 'who', 1234: 'whole', 1235: 'wholly', 1236: 'whom', 1237: 'whore!', 1238: 'whose', 1239: 'why', 1240: 'wife.', 1241: 'will', 1242: 'wind', 1243: 'wind.', 1244: 'window', 1245: 'window,', 1246: 'wipe', 1247: 'wiped', 1248: 'wiping', 1249: 'wished,', 1250: 'with', 1251: 'with?!', 1252: 'without', 1253: 'woke', 1254: 'women,', 1255: 'won‚Äôt', 1256: 'wood', 1257: 'wood.', 1258: 'word.', 1259: 'words', 1260: 'wore', 1261: 'worked', 1262: 'world.', 1263: 'worse', 1264: 'worse,', 1265: 'worsen', 1266: 'worsened', 1267: 'worst', 1268: 'worst-case', 1269: 'worthy', 1270: 'would', 1271: 'wouldn‚Äôt', 1272: 'wound', 1273: 'wounds', 1274: 'wounds.', 1275: 'wounds?!', 1276: 'wrapped', 1277: 'wrong', 1278: 'wushan', 1279: 'xiao', 1280: 'yawned,', 1281: 'year', 1282: 'years', 1283: 'yelling', 1284: 'yet', 1285: 'you', 1286: 'young', 1287: 'your', 1288: 'yourself', 1289: 'yourself?', 1290: 'youthful', 1291: 'you‚Äôll', 1292: 'you‚Äôre', 1293: 'yuheng', 1294: '‚Äúah‚Ä¶let', 1295: '‚Äúchu', 1296: '‚Äúcome', 1297: '‚Äúgonna', 1298: '‚Äúherein', 1299: '‚Äúi', 1300: '‚Äúif', 1301: '‚Äúit', 1302: '‚Äúi‚Äôm', 1303: '‚Äúone', 1304: '‚Äúpeople‚Äù', 1305: '‚Äúserves', 1306: '‚Äúshh‚Ä¶', 1307: '‚Äúshizun?', 1308: '‚Äúten', 1309: '‚Äúthat‚Äôs', 1310: '‚Äúthe', 1311: '‚Äúthere', 1312: '‚Äúwanning,', 1313: '‚Äúwe', 1314: '‚Äúwhat', 1315: '‚Äúwhatever‚Äîwhy', 1316: '‚Äúyou'}\n",
            "{'a': 0, 'able': 1, 'about': 2, 'about,': 3, 'about?!‚Äù': 4, 'absolutely': 5, 'absorbing': 6, 'across': 7, 'acted': 8, 'actually': 9, 'afar,': 10, 'afraid': 11, 'after': 12, 'afterward.': 13, 'again': 14, 'again!': 15, 'again.': 16, 'against': 17, 'age': 18, 'aggravation,': 19, 'ago,': 20, 'ah‚Ä¶never': 21, 'all': 22, 'all,': 23, 'all.': 24, 'allowed': 25, 'all‚Äîa': 26, 'almost': 27, 'alone': 28, 'already': 29, 'also': 30, 'an': 31, 'and': 32, 'anger': 33, 'angrily': 34, 'another': 35, 'ants': 36, 'any': 37, 'anyone': 38, 'appalled': 39, 'appearances.': 40, 'applied,': 41, 'applying': 42, 'are': 43, 'arm': 44, 'armored': 45, 'arms': 46, 'arms,': 47, 'arms.': 48, 'around': 49, 'array': 50, 'array?!': 51, 'array‚Ä¶': 52, 'art.': 53, 'as': 54, 'aside': 55, 'ask': 56, 'asked': 57, 'at': 58, 'ate': 59, 'automaton,': 60, 'automatons': 61, 'awake,': 62, 'away': 63, 'away,': 64, 'away‚Ä¶‚Äù': 65, 'back': 66, 'back,': 67, 'back.': 68, 'backbone,': 69, 'backlash': 70, 'back‚Äîthat': 71, 'bad': 72, 'bag,': 73, 'bamboo': 74, 'bandages': 75, 'bandaging': 76, 'bare': 77, 'bared': 78, 'barely': 79, 'barrier': 80, 'bat': 81, 'be': 82, 'be?!': 83, 'because': 84, 'bed': 85, 'bed,': 86, 'bed.': 87, 'bedroom.': 88, 'bedside,': 89, 'bedside.': 90, 'been': 91, 'before': 92, 'before.': 93, 'began': 94, 'begrudge': 95, 'behind': 96, 'being': 97, 'being‚Ä¶': 98, 'believed': 99, 'belly': 100, 'belonged': 101, 'belt': 102, 'beside': 103, 'better?': 104, 'between': 105, 'big,': 106, 'billowing': 107, 'birth': 108, 'bit': 109, 'bit,': 110, 'bitter': 111, 'bitter!‚Äù': 112, 'blazing': 113, 'bleeding.': 114, 'blew': 115, 'blink': 116, 'blood': 117, 'blood,': 118, 'blood.': 119, 'blood‚Ä¶': 120, 'bloomed': 121, 'blowing': 122, 'blue,': 123, 'body': 124, 'body,': 125, 'body.': 126, 'bone.': 127, 'bones': 128, 'born': 129, 'born,': 130, 'both': 131, 'bothering': 132, 'boundary,': 133, 'bow': 134, 'bowl': 135, 'brave': 136, 'breakfast,': 137, 'breath': 138, 'breathing': 139, 'breaths': 140, 'brewed': 141, 'bridge‚Äôs': 142, 'brilliant': 143, 'broad': 144, 'broke': 145, 'broken': 146, 'brother': 147, 'brother.‚Äù': 148, 'brothers.‚Äù': 149, 'brought': 150, 'bruises': 151, 'burst': 152, 'but': 153, 'but,': 154, 'by': 155, 'called': 156, 'came': 157, 'can': 158, 'candle.': 159, 'candlelight,': 160, 'candy': 161, 'care': 162, 'care.': 163, 'carried': 164, 'carrying': 165, 'catch': 166, 'caught': 167, 'cavalry': 168, 'ceaselessly,': 169, 'cedarwood.': 170, 'center.': 171, 'certain': 172, 'change': 173, 'chaste': 174, 'cheating': 175, 'chest,': 176, 'chest.': 177, 'chin': 178, 'chiye': 179, 'chu': 180, 'circle': 181, 'circumstances,': 182, 'clanking': 183, 'clean.': 184, 'clear': 185, 'clearly': 186, 'close': 187, 'closed': 188, 'closer': 189, 'closer,': 190, 'clothes.': 191, 'clothing': 192, 'cold': 193, 'cold,': 194, 'cold?!': 195, 'colder': 196, 'colder,': 197, 'cold‚Ä¶‚Äù': 198, 'collar': 199, 'collars': 200, 'come': 201, 'complaint.': 202, 'completely': 203, 'composed': 204, 'congee‚Ä¶‚Äù': 205, 'conjured': 206, 'considered': 207, 'continued': 208, 'continuously': 209, 'control.': 210, 'cool': 211, 'coppery': 212, 'core': 213, 'corner': 214, 'corners': 215, 'corpse.': 216, 'coughed': 217, 'could': 218, 'couldn‚Äôt': 219, 'could‚Äôve': 220, 'court': 221, 'covers': 222, 'cracked': 223, 'cradled': 224, 'cried‚Äîthat': 225, 'cry': 226, 'cultivation,': 227, 'curled': 228, 'currently': 229, 'curse': 230, 'cursed': 231, 'curtains.': 232, 'cut': 233, 'cut,': 234, 'cutting': 235, 'dajing.': 236, 'dajing.‚Äù': 237, 'damage.': 238, 'dare': 239, 'dared': 240, 'dare‚Ä¶': 241, 'daring': 242, 'day': 243, 'day,': 244, 'days': 245, 'daze.': 246, 'dazzled': 247, 'dead!': 248, 'dead.': 249, 'death,': 250, 'death.': 251, 'deaths.': 252, 'decades.': 253, 'deeper': 254, 'demand:': 255, 'descent': 256, 'desire': 257, 'devoured': 258, 'did': 259, 'didn‚Äôt': 260, 'die': 261, 'die!‚Äù': 262, 'died': 263, 'difficult': 264, 'dignity': 265, 'direction': 266, 'disappeared': 267, 'disciples': 268, 'discipline': 269, 'discomfort,': 270, 'discreetly': 271, 'disintegrate,': 272, 'dismounted.': 273, 'dispersed.': 274, 'distance': 275, 'distance.‚Äù': 276, 'distinguishable.': 277, 'do': 278, 'do.': 279, 'dog!': 280, 'dog,': 281, 'doing': 282, 'doing,': 283, 'done': 284, 'don‚Äôt': 285, 'door': 286, 'door,': 287, 'doorway,': 288, 'down': 289, 'down.': 290, 'downward': 291, 'doze,': 292, 'dozed': 293, 'drafty': 294, 'dragged': 295, 'dragging,': 296, 'drain': 297, 'drawn': 298, 'dream.': 299, 'dreams': 300, 'drenched': 301, 'dress': 302, 'drew': 303, 'drooped,': 304, 'dumbfounded.': 305, 'during': 306, 'dust': 307, 'dyed': 308, 'each': 309, 'eat': 310, 'ecstasy': 311, 'egg': 312, 'elder': 313, 'eldest': 314, 'elemental': 315, 'elements': 316, 'else': 317, 'embrace.‚Äù': 318, 'embracing': 319, 'emotions': 320, 'emperor': 321, 'empty': 322, 'empty,': 323, 'encounter': 324, 'end;': 325, 'ended': 326, 'enemy,': 327, 'energy': 328, 'energy,': 329, 'energy.': 330, 'enormous': 331, 'enraged': 332, 'enter': 333, 'entire': 334, 'entwined': 335, 'entwined,': 336, 'error‚Ä¶': 337, 'escaped': 338, 'essence': 339, 'eternal': 340, 'even': 341, 'every': 342, 'everything': 343, 'exhaustion': 344, 'existed': 345, 'exploded': 346, 'expression': 347, 'extent': 348, 'extremely': 349, 'eye,': 350, 'eyebrows': 351, 'eyelash.': 352, 'eyelashes': 353, 'eyes': 354, 'eyes,': 355, 'eyes.': 356, 'eyes‚Äîforever.‚Äù': 357, 'face': 358, 'face.': 359, 'faced': 360, 'faces': 361, 'fact': 362, 'fall': 363, 'fallen': 364, 'familiar': 365, 'familiarity': 366, 'fangxu': 367, 'fangxu.': 368, 'far': 369, 'favored': 370, 'fed': 371, 'feed': 372, 'feeding': 373, 'feel': 374, 'feet': 375, 'fell': 376, 'felt': 377, 'festered,': 378, 'festering.': 379, 'fever': 380, 'feverish': 381, 'feverish,': 382, 'few': 383, 'fierce': 384, 'figure,': 385, 'figuring': 386, 'filled': 387, 'finally': 388, 'finally,': 389, 'fine': 390, 'finished': 391, 'fireworks': 392, 'first': 393, 'five': 394, 'flame': 395, 'flame,': 396, 'flared': 397, 'fleeting': 398, 'flesh': 399, 'flora': 400, 'floral': 401, 'flow': 402, 'flowed': 403, 'flower': 404, 'flowers': 405, 'flushed': 406, 'fluttered': 407, 'fluttering': 408, 'foggy': 409, 'follow': 410, 'followed': 411, 'followed,': 412, 'following,': 413, 'foot': 414, 'for': 415, 'fortunately,': 416, 'forward.': 417, 'found': 418, 'fresh': 419, 'from': 420, 'front': 421, 'frowned,': 422, 'fucking': 423, 'further': 424, 'further,': 425, 'fuzzy.': 426, 'gall': 427, 'gather': 428, 'gaze': 429, 'gazed': 430, 'generation': 431, 'gently': 432, 'gently.': 433, 'get': 434, 'getting': 435, 'ghost': 436, 'glanced': 437, 'gnawing': 438, 'go': 439, 'goddamn': 440, 'going': 441, 'gone': 442, 'gone,': 443, 'gone.': 444, 'good,': 445, 'goodness': 446, 'got': 447, 'grab': 448, 'grass': 449, 'grave': 450, 'grew': 451, 'grimaced,': 452, 'groan': 453, 'groaned': 454, 'groaning': 455, 'ground': 456, 'growing': 457, 'grown': 458, 'gulp': 459, 'habit': 460, 'had': 461, 'had,': 462, 'hadn‚Äôt': 463, 'hair': 464, 'half': 465, 'half-asleep,': 466, 'half-open': 467, 'halfway': 468, 'hand,': 469, 'handle': 470, 'happened': 471, 'hard': 472, 'has': 473, 'hate': 474, 'hated': 475, 'hatred,': 476, 'have': 477, 'have‚Ä¶made': 478, 'having': 479, 'hazy': 480, 'he': 481, 'head': 482, 'head.': 483, 'headed': 484, 'healing': 485, 'healing.': 486, 'healthy': 487, 'hear': 488, 'heard': 489, 'hearing': 490, 'heart': 491, 'heart.': 492, 'heat': 493, 'heavier': 494, 'heavier.': 495, 'held': 496, 'hell': 497, 'hell.': 498, 'help': 499, 'helped': 500, 'her': 501, 'here': 502, 'here,': 503, 'here.': 504, 'here.‚Äù': 505, 'heroes.‚Äù': 506, 'he‚Äôd': 507, 'hidden': 508, 'high': 509, 'him': 510, 'him,': 511, 'him.': 512, 'himself': 513, 'himself,': 514, 'himself.': 515, 'himself:': 516, 'him‚Äîthis': 517, 'his': 518, 'his.': 519, 'hold': 520, 'holding': 521, 'hongyan': 522, 'hope': 523, 'horror,': 524, 'hot': 525, 'hour': 526, 'hour,': 527, 'how': 528, 'however,': 529, 'humid': 530, 'hundred': 531, 'i': 532, 'ice.': 533, 'idly': 534, 'if': 535, 'ignore': 536, 'illuminating': 537, 'imagined.': 538, 'immediately': 539, 'in': 540, 'in,': 541, 'in.': 542, 'indeed': 543, 'indignation,': 544, 'indulgence': 545, 'inexplicably,': 546, 'infected': 547, 'infirmary': 548, 'injury': 549, 'injury.': 550, 'inside': 551, 'insisted': 552, 'instant,': 553, 'instead': 554, 'instead,': 555, 'instead.': 556, 'integrity': 557, 'intensity,': 558, 'intensive': 559, 'intimate': 560, 'into': 561, 'involuntary': 562, 'irritation': 563, 'is': 564, 'it': 565, 'it,': 566, 'it.': 567, 'its': 568, 'itself.': 569, 'it‚Äôs': 570, 'it‚Ä¶': 571, 'jaw': 572, 'jealousy,': 573, 'jerking.': 574, 'joy': 575, 'just': 576, 'keeping': 577, 'kept': 578, 'kick': 579, 'kicked': 580, 'kind': 581, 'kiss': 582, 'kissed,': 583, 'knew': 584, 'knife': 585, 'know': 586, 'know.': 587, 'labored': 588, 'lad': 589, 'laid': 590, 'last': 591, 'late': 592, 'later,': 593, 'laughed': 594, 'lay': 595, 'layer': 596, 'lazily': 597, 'lean,': 598, 'leaned': 599, 'least.': 600, 'leave': 601, 'leaves.': 602, 'leaving': 603, 'left': 604, 'leg': 605, 'legs,': 606, 'let': 607, 'libei': 608, 'lie': 609, 'life': 610, 'life,': 611, 'life.': 612, 'life?': 613, 'lifeblood': 614, 'lifetime': 615, 'lifetime,': 616, 'lifetime.': 617, 'lifted': 618, 'light': 619, 'light,': 620, 'lightly': 621, 'lightning,': 622, 'like': 623, 'line': 624, 'lingering': 625, 'lips': 626, 'lips,': 627, 'lips.': 628, 'little': 629, 'location': 630, 'loneliness': 631, 'long': 632, 'longer': 633, 'longer.‚Äù': 634, 'longer‚Ä¶': 635, 'look': 636, 'looked': 637, 'lose': 638, 'lost': 639, 'lotus': 640, 'love': 641, 'loved': 642, 'lucid,': 643, 'lying': 644, 'm-mo': 645, 'madam': 646, 'made': 647, 'maintain': 648, 'make': 649, 'man': 650, 'man,': 651, 'man.': 652, 'many': 653, 'marched,': 654, 'matter': 655, 'matter.': 656, 'me': 657, 'meaning': 658, 'meat': 659, 'medicine': 660, 'medicine,': 661, 'medicine.‚Äù': 662, 'mei': 663, 'mei.': 664, 'memories': 665, 'men': 666, 'mend': 667, 'merely': 668, 'metal': 669, 'might': 670, 'mind': 671, 'mind.': 672, 'mind.‚Äù': 673, 'mind:': 674, 'missed': 675, 'mist': 676, 'mistress': 677, 'mo': 678, 'moment': 679, 'moment,': 680, 'monument': 681, 'monument,': 682, 'moonlight': 683, 'moral': 684, 'more': 685, 'morning': 686, 'morning,': 687, 'moron?!': 688, 'mortal': 689, 'most': 690, 'most,': 691, 'mother?‚Äù': 692, 'mottled': 693, 'mountains': 694, 'mountains,': 695, 'mountains.': 696, 'mouth': 697, 'mouth.': 698, 'mouthful': 699, 'mouthfuls.': 700, 'moved,': 701, 'movements': 702, 'moving': 703, 'much': 704, 'muddled': 705, 'mulishly': 706, 'murk': 707, 'murmured,': 708, 'murmuring,': 709, 'muscles,': 710, 'muster': 711, 'muttered.': 712, 'my': 713, 'nagging': 714, 'name': 715, 'names': 716, 'naturally,': 717, 'nature': 718, 'needed.': 719, 'never': 720, 'never-ending': 721, 'new': 722, 'next': 723, 'night': 724, 'night,': 725, 'night.': 726, 'no': 727, 'noise': 728, 'none': 729, 'nonsense': 730, 'not': 731, 'nothing': 732, 'now': 733, 'numb.': 734, 'occurred': 735, 'of': 736, 'off': 737, 'off.': 738, 'offense,': 739, 'okay‚Ä¶‚Ä¶‚Äù': 740, 'old': 741, 'on': 742, 'on,': 743, 'once': 744, 'one': 745, 'ones.': 746, 'only': 747, 'onto': 748, 'open': 749, 'open,': 750, 'open.': 751, 'opened': 752, 'or': 753, 'other': 754, 'others,': 755, 'out': 756, 'out,': 757, 'out.': 758, 'out?': 759, 'over': 760, 'over.': 761, 'own': 762, 'pain,': 763, 'pain.': 764, 'pained,': 765, 'palace.': 766, 'pale,': 767, 'paled,': 768, 'palm': 769, 'palm,': 770, 'palms': 771, 'panic.': 772, 'paper': 773, 'part': 774, 'parting': 775, 'passing': 776, 'passion': 777, 'past': 778, 'past,': 779, 'past.': 780, 'patiently': 781, 'peaceful': 782, 'peak': 783, 'people': 784, 'period': 785, 'person': 786, 'person.': 787, 'person‚Äôs': 788, 'pettily.': 789, 'phrase': 790, 'physical': 791, 'picked': 792, 'picture': 793, 'piece': 794, 'pillars,': 795, 'pillow': 796, 'pity': 797, 'place': 798, 'place,': 799, 'placed': 800, 'places': 801, 'places,': 802, 'point': 803, 'pointed': 804, 'pond': 805, 'pond,': 806, 'pond.': 807, 'pool': 808, 'pool.': 809, 'pooled': 810, 'possess.': 811, 'possible.': 812, 'poured': 813, 'power': 814, 'powerful': 815, 'precious': 816, 'press': 817, 'pressed': 818, 'pressing': 819, 'previous': 820, 'pride?': 821, 'probably': 822, 'problem': 823, 'process': 824, 'process,': 825, 'propped': 826, 'propriety.': 827, 'pulling': 828, 'punishment': 829, 'purpling': 830, 'pursing.': 831, 'pushing': 832, 'put': 833, 'quickly': 834, 'quilt': 835, 'quilt.': 836, 'rain,': 837, 'raising': 838, 'ran': 839, 'ran.': 840, 'ran‚Äôs': 841, 'rapidly': 842, 'rather': 843, 'ravish': 844, 'reach': 845, 'reach.': 846, 'reached': 847, 'reacted': 848, 'reaction': 849, 'real,': 850, 'realize': 851, 'realized': 852, 'really': 853, 'rebirth.': 854, 'reborn,': 855, 'receded.': 856, 'recklessly': 857, 'red.': 858, 'refused': 859, 'region,': 860, 'relations': 861, 'relief.': 862, 'reluctantly,': 863, 'remember': 864, 'remembered': 865, 'reminded': 866, 'resist': 867, 'respond.': 868, 'rest': 869, 'rest.': 870, 'rested': 871, 'restful': 872, 'return': 873, 'returned': 874, 'reunions': 875, 'revealed': 876, 'revealing': 877, 'reverse.': 878, 'rhythm,': 879, 'right': 880, 'right,‚Äù': 881, 'rise': 882, 'rivers': 883, 'robes,': 884, 'rod.': 885, 'room': 886, 'room.': 887, 'rotted': 888, 'roughly,': 889, 'rushed': 890, 'rusty,': 891, 'sacrifice': 892, 'said': 893, 'said,': 894, 'salve': 895, 'same': 896, 'sash': 897, 'sat': 898, 'saw': 899, 'say': 900, 'say,': 901, 'scalp': 902, 'scars': 903, 'scatter,': 904, 'scenario': 905, 'scent': 906, 'scrapped': 907, 'scrutinize': 908, 'sealed': 909, 'see': 910, 'seeing': 911, 'seemed': 912, 'seen': 913, 'seizing': 914, 'self': 915, 'sensation': 916, 'sense': 917, 'sent': 918, 'set': 919, 'setting': 920, 'settled': 921, 'several': 922, 'severe': 923, 'shake': 924, 'shallow': 925, 'shattered,': 926, 'sheets': 927, 'shh‚Ä¶': 928, 'shi': 929, 'shield': 930, 'shines': 931, 'shizun!‚Äù': 932, 'shizun.': 933, 'shizun‚Äôs': 934, 'shock,': 935, 'shone': 936, 'should': 937, 'shoulder.': 938, 'shoulders': 939, 'shoulders.': 940, 'shouting,': 941, 'show': 942, 'showed': 943, 'shuddering': 944, 'shut': 945, 'sichuan': 946, 'sigh': 947, 'sighed,': 948, 'sight': 949, 'signified': 950, 'silent,': 951, 'since': 952, 'single': 953, 'single-mindedly': 954, 'sip': 955, 'sisheng': 956, 'sixteen-year-old': 957, 'skin': 958, 'sky': 959, 'slapped': 960, 'sleep': 961, 'sleep,': 962, 'sleep.': 963, 'sleep?': 964, 'sleeping': 965, 'sleeping.': 966, 'slender': 967, 'slept': 968, 'sliced': 969, 'slightest.': 970, 'slightly': 971, 'slipped': 972, 'sloppily,': 973, 'slowly': 974, 'slumber.': 975, 'small': 976, 'smiled': 977, 'sneak': 978, 'so': 979, 'so,': 980, 'so-called': 981, 'softly': 982, 'solved!‚Äù': 983, 'somber': 984, 'some': 985, 'someone': 986, 'something': 987, 'sorrow': 988, 'sound,': 989, 'speech,': 990, 'speechless.': 991, 'spent': 992, 'spirit': 993, 'spirits': 994, 'spirits.': 995, 'spiritual': 996, 'splashed': 997, 'spoonful': 998, 'spoonfuls': 999, 'spot.': 1000, 'spot.‚Äù': 1001, 'spots': 1002, 'spread': 1003, 'squinted': 1004, 'stab': 1005, 'staining': 1006, 'stalked': 1007, 'stand': 1008, 'stared.': 1009, 'stars': 1010, 'started': 1011, 'startled,': 1012, 'state': 1013, 'state,': 1014, 'staunch': 1015, 'steady.': 1016, 'steps': 1017, 'sterilizing': 1018, 'stiff': 1019, 'stifled': 1020, 'still': 1021, 'still,': 1022, 'stock-still.': 1023, 'stone': 1024, 'stood': 1025, 'stop': 1026, 'streaks': 1027, 'strikes': 1028, 'stroked': 1029, 'strong': 1030, 'struck': 1031, 'stubborn': 1032, 'stubborn?': 1033, 'stupid': 1034, 'subconsciously': 1035, 'submerged': 1036, 'such': 1037, 'suck': 1038, 'suddenly,': 1039, 'suffered': 1040, 'suining.': 1041, 'sun': 1042, 'sun,': 1043, 'sun.': 1044, 'support': 1045, 'supporting': 1046, 'suppress': 1047, 'sure': 1048, 'sweat': 1049, 'swiftly': 1050, 'swore': 1051, 'take': 1052, 'taking': 1053, 'talking': 1054, 'taste': 1055, 'tasted': 1056, 'taut': 1057, 'taxian\\x02jun,': 1058, 'taxian-jun': 1059, 'technique': 1060, 'technique!': 1061, 'tell': 1062, 'temper': 1063, 'temples,': 1064, 'ten': 1065, 'tender': 1066, 'terrible': 1067, 'test': 1068, 'than': 1069, 'that': 1070, 'that,': 1071, 'that‚Äôs': 1072, 'the': 1073, 'their': 1074, 'them': 1075, 'them,': 1076, 'them.': 1077, 'then': 1078, 'then,': 1079, 'there': 1080, 'these': 1081, 'they': 1082, 'thick': 1083, 'thing': 1084, 'thing.': 1085, 'things': 1086, 'things.': 1087, 'things;': 1088, 'think': 1089, 'thirty-two-year-old': 1090, 'this': 1091, 'this,': 1092, 'this.': 1093, 'this?': 1094, 'those': 1095, 'those‚Äîthose': 1096, 'though': 1097, 'though,': 1098, 'thought': 1099, 'thousand': 1100, 'three': 1101, 'throat': 1102, 'through': 1103, 'through.': 1104, 'throw': 1105, 'throwing': 1106, 'thrown': 1107, 'thump.': 1108, 'tianwen,': 1109, 'time': 1110, 'time,': 1111, 'timelessness': 1112, 'times': 1113, 'times,': 1114, 'tipped': 1115, 'tired': 1116, 'to': 1117, 'to.': 1118, 'together': 1119, 'together.': 1120, 'tongue': 1121, 'tongue.': 1122, 'too': 1123, 'too,': 1124, 'too.': 1125, 'took': 1126, 'top': 1127, 'tore': 1128, 'torn': 1129, 'torrent.': 1130, 'tossing': 1131, 'touch': 1132, 'tousled': 1133, 'toward': 1134, 'towel': 1135, 'to‚Ä¶': 1136, 'transfer': 1137, 'treat': 1138, 'trembling': 1139, 'tried': 1140, 'true': 1141, 'truly': 1142, 'truth.': 1143, 'tucked': 1144, 'turmoil,': 1145, 'turned': 1146, 'turning,': 1147, 'twinge': 1148, 'two': 1149, 'two,': 1150, 'two-faced,': 1151, 'unable': 1152, 'unbroken.': 1153, 'unconscious': 1154, 'unconscious,': 1155, 'unconscious.': 1156, 'under': 1157, 'unevenly': 1158, 'unfortunately,': 1159, 'unique': 1160, 'universe.': 1161, 'unmoving,': 1162, 'unseen': 1163, 'until': 1164, 'unyielding': 1165, 'up': 1166, 'up,': 1167, 'up.': 1168, 'upon': 1169, 'upper': 1170, 'used': 1171, 'using': 1172, 'usual': 1173, 'usually': 1174, 'usually,': 1175, 'utter': 1176, 'utterly': 1177, 'vaguely,': 1178, 'vanished': 1179, 'vaulted': 1180, 'veil': 1181, 'venerable': 1182, 'versa,': 1183, 'very': 1184, 'vestige': 1185, 'vice': 1186, 'vicious': 1187, 'voice': 1188, 'wading': 1189, 'waist': 1190, 'walked': 1191, 'walking': 1192, 'wang‚Äôs': 1193, 'wanning': 1194, 'wanning!‚Äù': 1195, 'wanning,': 1196, 'wanning.': 1197, 'wanning?': 1198, 'wanning‚Äôs': 1199, 'want': 1200, 'wanted,': 1201, 'warmth': 1202, 'warning.': 1203, 'was': 1204, 'was,': 1205, 'washed': 1206, 'wasn‚Äôt': 1207, 'watch': 1208, 'watched.': 1209, 'water': 1210, 'water,': 1211, 'water‚Ä¶': 1212, 'waves': 1213, 'way': 1214, 'we': 1215, 'weakness': 1216, 'weave': 1217, 'weiyu': 1218, 'weiyu?!': 1219, 'well': 1220, 'went': 1221, 'were': 1222, 'west.': 1223, 'wetness': 1224, 'what': 1225, 'when': 1226, 'where': 1227, 'which': 1228, 'while': 1229, 'while,': 1230, 'white': 1231, 'white.': 1232, 'who': 1233, 'whole': 1234, 'wholly': 1235, 'whom': 1236, 'whore!': 1237, 'whose': 1238, 'why': 1239, 'wife.': 1240, 'will': 1241, 'wind': 1242, 'wind.': 1243, 'window': 1244, 'window,': 1245, 'wipe': 1246, 'wiped': 1247, 'wiping': 1248, 'wished,': 1249, 'with': 1250, 'with?!': 1251, 'without': 1252, 'woke': 1253, 'women,': 1254, 'won‚Äôt': 1255, 'wood': 1256, 'wood.': 1257, 'word.': 1258, 'words': 1259, 'wore': 1260, 'worked': 1261, 'world.': 1262, 'worse': 1263, 'worse,': 1264, 'worsen': 1265, 'worsened': 1266, 'worst': 1267, 'worst-case': 1268, 'worthy': 1269, 'would': 1270, 'wouldn‚Äôt': 1271, 'wound': 1272, 'wounds': 1273, 'wounds.': 1274, 'wounds?!': 1275, 'wrapped': 1276, 'wrong': 1277, 'wushan': 1278, 'xiao': 1279, 'yawned,': 1280, 'year': 1281, 'years': 1282, 'yelling': 1283, 'yet': 1284, 'you': 1285, 'young': 1286, 'your': 1287, 'yourself': 1288, 'yourself?': 1289, 'youthful': 1290, 'you‚Äôll': 1291, 'you‚Äôre': 1292, 'yuheng': 1293, '‚Äúah‚Ä¶let': 1294, '‚Äúchu': 1295, '‚Äúcome': 1296, '‚Äúgonna': 1297, '‚Äúherein': 1298, '‚Äúi': 1299, '‚Äúif': 1300, '‚Äúit': 1301, '‚Äúi‚Äôm': 1302, '‚Äúone': 1303, '‚Äúpeople‚Äù': 1304, '‚Äúserves': 1305, '‚Äúshh‚Ä¶': 1306, '‚Äúshizun?': 1307, '‚Äúten': 1308, '‚Äúthat‚Äôs': 1309, '‚Äúthe': 1310, '‚Äúthere': 1311, '‚Äúwanning,': 1312, '‚Äúwe': 1313, '‚Äúwhat': 1314, '‚Äúwhatever‚Äîwhy': 1315, '‚Äúyou': 1316}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(unique_words)\n",
        "text_size=len(text)\n",
        "print(vocab_size)\n",
        "print(text_size)\n",
        "seq_length=30\n",
        "\n",
        "in_seq=[]\n",
        "nxt_seq=[]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8RXq90pvKz8",
        "outputId": "658a3770-d774-4e38-a982-f71c82fa0772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1317\n",
            "3663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(0, (text_size-seq_length),1):\n",
        "\n",
        "  if i==3633:\n",
        "    break\n",
        "\n",
        "  input_seq=text[i:i+seq_length]\n",
        "  output_wrd=text[i+seq_length]\n",
        "\n",
        "  in_seq.append([word_2_int[word] for word in input_seq])\n",
        "  nxt_seq.append(word_2_int[output_wrd])\n",
        "\n"
      ],
      "metadata": {
        "id": "_hJG97M7xSWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X=np.array(in_seq)\n",
        "y=np.array(nxt_seq)\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMaLzEQP3LbW",
        "outputId": "ec2af360-f39f-4384-f8a2-8f2c22b53598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3633, 30) (3633,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "\n",
        "model=Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=70, input_length=None),\n",
        "    SimpleRNN(128, return_sequences=True),\n",
        "    SimpleRNN(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "NzaXehQ43kbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding layer: converts words into vectors to be fed into a ANN.\n",
        "ex : word \"cat\" could become [0.2, -0.5, 0.9]\n",
        "\n",
        "\n",
        "\n",
        "vectors can capture semantic meanings, and reduce dimensions.\n",
        "\n",
        "\n",
        "\n",
        "suppose our vocabulary consists of 4 words. [cat, dog, fish, bird]\n",
        "If we use traditional one-hot encoding thse would be represented as follows\n",
        "\n",
        "\n",
        "\"cat\" is represented as [1, 0, 0, 0]\n",
        "\"dog\" is represented as [0, 1, 0, 0]\n",
        "\"fish\" is represented as [0, 0, 1, 0]\n",
        "\"bird\" is represented as [0, 0, 0, 1]\n",
        "\n",
        "\n",
        "\n",
        "4 dimensions are needed to represent a word in vocabulary with 4 words so dimesions=vocabulary size. if the vocabulary is large, then one hot encoding would produce sparse high dimensional representations.\n",
        "\n",
        "\n",
        "\n",
        "but in embedding this would be something like\n",
        "\n",
        "\n",
        "\"cat\" might be represented as [0.2, 0.9]\n",
        "\"dog\" might be represented as [-0.1, 0.8]\n",
        "\"fish\" might be represented as [0.6, -0.5]\n",
        "\"bird\" might be represented as [-0.3, -0.7]\n",
        ".\n",
        "\n",
        "\n",
        "similar words have similar vector representations in embedding but in one hot encoding there's nothing like that. so embedding can capture semantic information while one hot encoding can't\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "\n",
        "input length is None so that it can predict from sequences of varying length\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "Embedding layer parameters:\n",
        "\n",
        "input_dim : no of unique inputs that embedding layers would be able to handle (size of the vocabulary)\n",
        "\n",
        "output_dim : dimesion of the output vector. Ex: if output_dim is k then the words will be represented as k-dimension vectors\n",
        "\n",
        "input_length= sequence length of the input sequence to the model"
      ],
      "metadata": {
        "id": "Js-tprHM6RDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wgwba1Hp9J-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMhnqeue-kBs",
        "outputId": "3f22ec31-0485-461b-8a36-da93a4bc8404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 6s 66ms/step - loss: 6.6358 - accuracy: 0.0457\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 6.4743 - accuracy: 0.0484\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 6.1781 - accuracy: 0.0564\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 6.1427 - accuracy: 0.0567\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 6.1173 - accuracy: 0.0570\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 3s 55ms/step - loss: 6.0607 - accuracy: 0.0575\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 3s 56ms/step - loss: 5.9864 - accuracy: 0.0586\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 5.9037 - accuracy: 0.0592\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 5.7893 - accuracy: 0.0611\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 5.6780 - accuracy: 0.0721\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 5.5135 - accuracy: 0.0738\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 4s 65ms/step - loss: 5.2990 - accuracy: 0.0848\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 3s 48ms/step - loss: 5.0756 - accuracy: 0.1027\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 4.8709 - accuracy: 0.1170\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 4.6915 - accuracy: 0.1258\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 4.4888 - accuracy: 0.1442\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 3s 47ms/step - loss: 4.3162 - accuracy: 0.1583\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 4s 65ms/step - loss: 4.1709 - accuracy: 0.1753\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 4.0524 - accuracy: 0.1916\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.9300 - accuracy: 0.1963\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.7665 - accuracy: 0.2227\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.5838 - accuracy: 0.2466\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 3s 55ms/step - loss: 3.5108 - accuracy: 0.2579\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 3s 56ms/step - loss: 3.3896 - accuracy: 0.2664\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.2159 - accuracy: 0.3009\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.3696 - accuracy: 0.2744\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 3.1341 - accuracy: 0.3094\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 2.9036 - accuracy: 0.3677\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 3s 62ms/step - loss: 2.7723 - accuracy: 0.3903\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 3s 50ms/step - loss: 2.6455 - accuracy: 0.4211\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 2.5231 - accuracy: 0.4432\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 2.4148 - accuracy: 0.4853\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 2.3054 - accuracy: 0.5156\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 2s 44ms/step - loss: 2.2105 - accuracy: 0.5497\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 4s 68ms/step - loss: 2.0942 - accuracy: 0.5734\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 1.9934 - accuracy: 0.6116\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.9031 - accuracy: 0.6287\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.9355 - accuracy: 0.6146\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.7974 - accuracy: 0.6625\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 3s 55ms/step - loss: 1.6623 - accuracy: 0.6942\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 3s 59ms/step - loss: 1.5278 - accuracy: 0.7371\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 1.4615 - accuracy: 0.7570\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.3840 - accuracy: 0.7746\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.3547 - accuracy: 0.7798\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 1.5378 - accuracy: 0.7256\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 4s 65ms/step - loss: 1.3304 - accuracy: 0.7781\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 3s 48ms/step - loss: 1.1793 - accuracy: 0.8192\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 1.1011 - accuracy: 0.8445\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.9661 - accuracy: 0.8836\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.8896 - accuracy: 0.9017\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 3s 47ms/step - loss: 0.8359 - accuracy: 0.9064\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 4s 64ms/step - loss: 0.7533 - accuracy: 0.9232\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.6803 - accuracy: 0.9389\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.6515 - accuracy: 0.9361\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.6176 - accuracy: 0.9455\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.5452 - accuracy: 0.9587\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 3s 58ms/step - loss: 0.6344 - accuracy: 0.9356\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 3s 55ms/step - loss: 1.0048 - accuracy: 0.8409\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.8927 - accuracy: 0.8640\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.6570 - accuracy: 0.9254\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.5108 - accuracy: 0.9549\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.4317 - accuracy: 0.9681\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 4s 69ms/step - loss: 0.3742 - accuracy: 0.9796\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 3s 45ms/step - loss: 0.4843 - accuracy: 0.9543\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 1.2150 - accuracy: 0.7647\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 1.0272 - accuracy: 0.8172\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.8584 - accuracy: 0.8533\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 3s 53ms/step - loss: 0.6234 - accuracy: 0.9160\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 4s 70ms/step - loss: 0.5824 - accuracy: 0.9213\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.4779 - accuracy: 0.9483\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.4165 - accuracy: 0.9576\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.3062 - accuracy: 0.9788\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.2568 - accuracy: 0.9879\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 4s 70ms/step - loss: 0.2797 - accuracy: 0.9824\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 4s 74ms/step - loss: 0.2376 - accuracy: 0.9868\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 3s 45ms/step - loss: 0.1995 - accuracy: 0.9909\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 0.1709 - accuracy: 0.9937\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1555 - accuracy: 0.9945\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 3s 44ms/step - loss: 0.1442 - accuracy: 0.9953\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 4s 70ms/step - loss: 0.1316 - accuracy: 0.9961\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.1208 - accuracy: 0.9972\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1129 - accuracy: 0.9975\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1052 - accuracy: 0.9975\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 2s 37ms/step - loss: 0.0985 - accuracy: 0.9989\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 3s 54ms/step - loss: 0.0923 - accuracy: 0.9986\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 3s 59ms/step - loss: 0.0872 - accuracy: 0.9992\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0824 - accuracy: 0.9992\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0778 - accuracy: 0.9994\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0733 - accuracy: 0.9997\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0694 - accuracy: 0.9997\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 4s 67ms/step - loss: 0.0658 - accuracy: 0.9997\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 3s 48ms/step - loss: 0.0625 - accuracy: 0.9997\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0600 - accuracy: 0.9997\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0568 - accuracy: 0.9997\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0541 - accuracy: 0.9997\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 3s 49ms/step - loss: 0.0516 - accuracy: 0.9997\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 4s 65ms/step - loss: 0.0492 - accuracy: 0.9997\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0470 - accuracy: 0.9997\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 0.0430 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2f33a34c40>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text='Mo Ran and Xiao Chiye both ran to '\n",
        "# seed_text=preprocess(seed_text)\n",
        "generated_text=[]\n",
        "\n",
        "predicted_words=[]\n",
        "\n",
        "for i in range(50):\n",
        "    input_seq = [word_2_int[word] for word in seed_text.lower().split()[-seq_length:]]\n",
        "    input_seq = np.array(input_seq).reshape(1, -1)\n",
        "    predicted_word_index = np.argmax(model.predict(input_seq), axis=-1).item()\n",
        "    predicted_word = int_2_word[predicted_word_index]\n",
        "    predicted_words.append(predicted_word)\n",
        "    seed_text+=\" \"+predicted_word\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"List of all predicted words:\\t\", predicted_words,\"\\n\\n\")\n",
        "print(seed_text)"
      ],
      "metadata": {
        "id": "eqFRnr6T-tis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8457388a-fb2d-4022-e95e-c75da109d9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "List of all predicted words:\t ['to', 'the', 'spots', 'here.‚Äù', '‚Äúwhat', 'about', 'my', 'mother?‚Äù', 'xiao', '‚Äúwhat', 'the', 'same', 'fact', 'off', 'this,', 'no', 'one', 'out.', 'he', 'had', 'been', 'it', 'said', 'and', 'you‚Äôll', 'bow', 'half', 'half-open', 'and', 'flora', 'never', 'have', 'out', 'supporting', 'an', 'wounds.', 'and', 'felt', 'as', 'up', 'he', 'would', 'be', 'that', 'day,', 'let', 'it', 'out', 'i', 'had'] \n",
            "\n",
            "\n",
            "Mo Ran and Xiao Chiye both ran to  to the spots here.‚Äù ‚Äúwhat about my mother?‚Äù xiao ‚Äúwhat the same fact off this, no one out. he had been it said and you‚Äôll bow half half-open and flora never have out supporting an wounds. and felt as up he would be that day, let it out i had\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONSTRUCTING THE MODEL AS AN LSTM"
      ],
      "metadata": {
        "id": "8RIndP7p4tHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model2=Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=70, input_length=None),\n",
        "    Dropout(0.2),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "KWhDYZoH4lx2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "iB4XQCnN6P63"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size=64, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8iyMx_f7XS9",
        "outputId": "0b95c36c-0e73-4750-db21-21d3357bd8a5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "57/57 [==============================] - 4s 41ms/step - loss: 0.1769 - accuracy: 0.9854\n",
            "Epoch 2/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.1477 - accuracy: 0.9879\n",
            "Epoch 3/100\n",
            "57/57 [==============================] - 3s 49ms/step - loss: 0.1096 - accuracy: 0.9928\n",
            "Epoch 4/100\n",
            "57/57 [==============================] - 4s 64ms/step - loss: 0.0754 - accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0542 - accuracy: 0.9992\n",
            "Epoch 6/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0404 - accuracy: 0.9994\n",
            "Epoch 7/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0348 - accuracy: 0.9997\n",
            "Epoch 8/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.2959 - accuracy: 0.9436\n",
            "Epoch 9/100\n",
            "57/57 [==============================] - 4s 62ms/step - loss: 0.5718 - accuracy: 0.8847\n",
            "Epoch 10/100\n",
            "57/57 [==============================] - 3s 51ms/step - loss: 0.2496 - accuracy: 0.9617\n",
            "Epoch 11/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.1113 - accuracy: 0.9923\n",
            "Epoch 12/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1041 - accuracy: 0.9906\n",
            "Epoch 13/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0680 - accuracy: 0.9953\n",
            "Epoch 14/100\n",
            "57/57 [==============================] - 2s 43ms/step - loss: 0.0643 - accuracy: 0.9953\n",
            "Epoch 15/100\n",
            "57/57 [==============================] - 4s 70ms/step - loss: 0.3299 - accuracy: 0.9367\n",
            "Epoch 16/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.5223 - accuracy: 0.8932\n",
            "Epoch 17/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.2342 - accuracy: 0.9634\n",
            "Epoch 18/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1305 - accuracy: 0.9857\n",
            "Epoch 19/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0797 - accuracy: 0.9917\n",
            "Epoch 20/100\n",
            "57/57 [==============================] - 3s 58ms/step - loss: 0.0867 - accuracy: 0.9895\n",
            "Epoch 21/100\n",
            "57/57 [==============================] - 3s 57ms/step - loss: 0.3184 - accuracy: 0.9474\n",
            "Epoch 22/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.1198 - accuracy: 0.9860\n",
            "Epoch 23/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0642 - accuracy: 0.9953\n",
            "Epoch 24/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0457 - accuracy: 0.9978\n",
            "Epoch 25/100\n",
            "57/57 [==============================] - 3s 53ms/step - loss: 0.0344 - accuracy: 0.9986\n",
            "Epoch 26/100\n",
            "57/57 [==============================] - 4s 75ms/step - loss: 0.0267 - accuracy: 0.9997\n",
            "Epoch 27/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0230 - accuracy: 0.9997\n",
            "Epoch 28/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0234 - accuracy: 0.9997\n",
            "Epoch 29/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0215 - accuracy: 0.9994\n",
            "Epoch 30/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "57/57 [==============================] - 4s 70ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "57/57 [==============================] - 3s 46ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "57/57 [==============================] - 3s 57ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "57/57 [==============================] - 3s 58ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "57/57 [==============================] - 4s 69ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "57/57 [==============================] - 3s 44ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "57/57 [==============================] - 3s 59ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "57/57 [==============================] - 3s 57ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "57/57 [==============================] - 2s 43ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "57/57 [==============================] - 3s 47ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "57/57 [==============================] - 4s 69ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "57/57 [==============================] - 4s 63ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "57/57 [==============================] - 3s 54ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "57/57 [==============================] - 3s 50ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "57/57 [==============================] - 4s 64ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "57/57 [==============================] - 4s 66ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "57/57 [==============================] - 4s 67ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "57/57 [==============================] - 3s 58ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "57/57 [==============================] - 3s 46ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "57/57 [==============================] - 4s 67ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "57/57 [==============================] - 4s 63ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "57/57 [==============================] - 3s 53ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "57/57 [==============================] - 3s 46ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "57/57 [==============================] - 4s 68ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "57/57 [==============================] - 3s 59ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "57/57 [==============================] - 3s 58ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "57/57 [==============================] - 2s 41ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "57/57 [==============================] - 2s 40ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "57/57 [==============================] - 4s 67ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "57/57 [==============================] - 3s 44ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "57/57 [==============================] - 2s 42ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "57/57 [==============================] - 2s 38ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0019 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2f3a5c8040>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text='Mo Ran and Xiao Chiye both ran to '\n",
        "# seed_text=preprocess(seed_text)\n",
        "generated_text=[]\n",
        "\n",
        "predicted_words=[]\n",
        "\n",
        "for i in range(50):\n",
        "    input_seq = [word_2_int[word] for word in seed_text.lower().split()[-seq_length:]]\n",
        "    input_seq = np.array(input_seq).reshape(1, -1)\n",
        "    predicted_word_index = np.argmax(model.predict(input_seq), axis=-1).item()\n",
        "    predicted_word = int_2_word[predicted_word_index]\n",
        "    predicted_words.append(predicted_word)\n",
        "    seed_text+=\" \"+predicted_word\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"List of all predicted words:\\t\", predicted_words,\"\\n\\n\")\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02oEKWIK9rvw",
        "outputId": "4a4eca55-423a-4d64-91e4-54c9f825ae28"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 426ms/step\n",
            "1/1 [==============================] - 0s 318ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "List of all predicted words:\t ['to', 'the', 'way', 'and', 'to', 'day,', 'under', 'his', 'wounds.', 'and', 'powerful', 'had', 'cutting', 'brother', 'sliced', 'away,', 'together.', 'mo', 'ran', 'had', 'used', 'in', 'into', 'the', 'long', 'hair', 'he', 'birth', 'the', 'back', 'on', 'his', 'word.', 'and', 'temper', 'flared', 'and', 'your', 'eldest', 'and', 'temper', 'in', 'the', 'light,', 'at', 'the', 'wind.', 'holding', 'to', 'ran.'] \n",
            "\n",
            "\n",
            "Mo Ran and Xiao Chiye both ran to  to the way and to day, under his wounds. and powerful had cutting brother sliced away, together. mo ran had used in into the long hair he birth the back on his word. and temper flared and your eldest and temper in the light, at the wind. holding to ran.\n"
          ]
        }
      ]
    }
  ]
}